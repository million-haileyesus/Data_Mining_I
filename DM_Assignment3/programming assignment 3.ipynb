{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03e151ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpmax, fpgrowth\n",
    "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, KFold, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731d5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    dataset = []\n",
    "    csv_file = \"../Grocery_Items_21.csv\"\n",
    "    data = pd.read_csv(f\"{csv_file}\")\n",
    "    \n",
    "    for i in range(len(data)):\n",
    "        row_values = data.iloc[i].values\n",
    "        items = [item.strip() for item in row_values if pd.notna(item)]\n",
    "        dataset.append(items)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92376bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_association_rules():    \n",
    "    dataset = get_dataset()   \n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(dataset).transform(dataset)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = fpgrowth(df, min_support=0.01, use_colnames=True)\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
    "    print(frequent_itemsets)\n",
    "get_association_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1f3115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_association():\n",
    "    minimum_support=values = [0.001, 0.005, 0.01, 0.05]\n",
    "    minimum_confidence_threshold = [0.05, 0.075, 0.1]\n",
    "    dataset = get_dataset()   \n",
    "\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(dataset).transform(dataset)\n",
    "    df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "    frequent_itemsets = []\n",
    "    rules = []\n",
    "    for min_supp in minimum_support:\n",
    "        for min_thresh in minimum_confidence_threshold:\n",
    "            frequent_itemsets.append(fpgrowth(df, min_support=min_supp, use_colnames=True))\n",
    "            rules.append(association_rules(frequent_itemsets[-1], metric=\"confidence\", min_threshold=min_thresh))\n",
    "    \n",
    "    glue = rules.pivot(index=\"Model\", columns=\"Task\", values=\"Score\")\n",
    "    sns.heatmap(glue, annot=True, fmt=\".1f\")\n",
    "\n",
    "extract_association()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fe9fc8",
   "metadata": {},
   "source": [
    "# Image Classification using CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de2a43a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grayscale_conversion():\n",
    "    folders = [\"n02102318-cocker_spaniel\", \"n02105056-groenendael\", \"n02106382-Bouvier_des_Flandres\",\n",
    "               \"n02107574-Greater_Swiss_Mountain_dog\"]\n",
    "    \n",
    "    no_of_images = []\n",
    "    for folder in folders:\n",
    "        files = [f for f in os.listdir(f\"../Cropped/{folder}\") if os.path.isfile(os.path.join(f\"../Cropped/{folder}\", f))]\n",
    "        no_of_images.append(len(files))\n",
    "\n",
    "    collect = {}\n",
    "    for folder, count in zip(folders, no_of_images):\n",
    "        all_files = os.listdir(f\"../Cropped/{folder}\")\n",
    "        collect[folder] = all_files\n",
    "        \n",
    "    \n",
    "    grayscaled_images = {}\n",
    "    for folder, images in collect.items():\n",
    "        combine = []\n",
    "        for img in images:\n",
    "            path = f\"../Cropped/{folder}/{img}\"\n",
    "            loaded_image = cv.imread(path)\n",
    "            combine.append(cv.cvtColor(loaded_image, cv.COLOR_BGR2GRAY))\n",
    "        grayscaled_images[folder] = combine\n",
    "    \n",
    "    return grayscaled_images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "deadff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset():\n",
    "    grayscaled_images = grayscale_conversion()\n",
    "    \n",
    "    training_set = {}\n",
    "    testing_set = {}\n",
    "    for folder in grayscaled_images:\n",
    "        perce_80 = int(len(grayscaled_images[folder]) * 0.8)\n",
    "        training_set[folder] = random.sample(grayscaled_images[folder], perce_80)\n",
    " \n",
    "    for folder, images in grayscaled_images.items():\n",
    "        combine = []\n",
    "        for img in images:\n",
    "            if not np.all(np.equal(img, training_set[folder]), axis=1).any():\n",
    "                combine.append(img)             \n",
    "        testing_set[folder] = combine\n",
    "    \n",
    "    return training_set, testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "edeb4e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split():\n",
    "    training_set, testing_set = split_dataset()\n",
    "    \n",
    "    X_train, y_train, X_test, y_test = ([] for i in range(4))\n",
    "    \n",
    "    count = 0\n",
    "    for training_folder in training_set:\n",
    "        for training_image in training_set[training_folder]:\n",
    "            X_train.append(training_image.ravel())\n",
    "            y_train.append(count)\n",
    "        count += 1\n",
    "    \n",
    "    count = 0\n",
    "    for testing_folder in testing_set:\n",
    "        for testing_image in testing_set[testing_folder]:\n",
    "            X_test.append(testing_image.ravel())\n",
    "            y_test.append(count)\n",
    "        count += 1\n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.array(y_test)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8779a323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardized_dataset():\n",
    "    a, y_train, b, y_test = train_test_split()\n",
    "     \n",
    "    standard = StandardScaler()\n",
    "    X_train = standard.fit_transform(a)\n",
    "    X_test = standard.transform(b)\n",
    "        \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19e9991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def images_classifier():\n",
    "    num_classes = 4\n",
    "    input_shape = (100, 100, 1)\n",
    "    \n",
    "    model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape), \n",
    "        layers.Conv2D(8, kernel_size=(3, 3), activation=\"relu\"), \n",
    "        layers.MaxPooling2D(pool_size=(2, 2)), \n",
    "        layers.Flatten(), \n",
    "        layers.Dense(16, activation=\"relu\"), \n",
    "        layers.Dense(num_classes, activation=\"softmax\")\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0f5d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    batch_size = 256\n",
    "    num_epochs = 100\n",
    "    model = images_classifier()\n",
    "    X_train, y_train, X_test, y_test = standardized_dataset()\n",
    "    \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], 100, 100, 1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], 100, 100, 1))\n",
    "    y_train = to_categorical(y_train, num_classes=4)\n",
    "    y_test = to_categorical(y_test, num_classes=4)\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "    model.fit(X_train, y_train, batch_size=batch_size, epochs=num_epochs, validation_split=0.2)\n",
    "    \n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5cb7c7b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 98, 98, 8)         80        \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPooli  (None, 49, 49, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 19208)             0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 16)                307344    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 307492 (1.17 MB)\n",
      "Trainable params: 307492 (1.17 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 370ms/step - loss: 1.6458 - accuracy: 0.3301 - val_loss: 4.7255 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 1.6651 - accuracy: 0.3446 - val_loss: 2.7003 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 1.0787 - accuracy: 0.5373 - val_loss: 3.0716 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 1.2125 - accuracy: 0.5012 - val_loss: 2.6124 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 1.0232 - accuracy: 0.5759 - val_loss: 1.8967 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.9361 - accuracy: 0.6554 - val_loss: 1.7020 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.9623 - accuracy: 0.6699 - val_loss: 1.7243 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.8915 - accuracy: 0.6819 - val_loss: 1.8482 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.8060 - accuracy: 0.7349 - val_loss: 2.1569 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.7907 - accuracy: 0.7301 - val_loss: 2.3839 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.7730 - accuracy: 0.7157 - val_loss: 2.2508 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.7126 - accuracy: 0.7446 - val_loss: 1.9732 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.6760 - accuracy: 0.7855 - val_loss: 1.8561 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 86ms/step - loss: 0.6547 - accuracy: 0.7880 - val_loss: 1.9308 - val_accuracy: 0.0096\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.6192 - accuracy: 0.8072 - val_loss: 1.9141 - val_accuracy: 0.0577\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 108ms/step - loss: 0.5844 - accuracy: 0.8193 - val_loss: 2.0201 - val_accuracy: 0.0673\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.5507 - accuracy: 0.8265 - val_loss: 2.1552 - val_accuracy: 0.0673\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 100ms/step - loss: 0.5162 - accuracy: 0.8410 - val_loss: 2.0497 - val_accuracy: 0.0962\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.4796 - accuracy: 0.8651 - val_loss: 1.8971 - val_accuracy: 0.1250\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 85ms/step - loss: 0.4512 - accuracy: 0.8819 - val_loss: 1.8371 - val_accuracy: 0.1827\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.4128 - accuracy: 0.9012 - val_loss: 1.8640 - val_accuracy: 0.1827\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.3779 - accuracy: 0.9157 - val_loss: 1.8372 - val_accuracy: 0.2115\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 119ms/step - loss: 0.3458 - accuracy: 0.9253 - val_loss: 1.8939 - val_accuracy: 0.2115\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.3103 - accuracy: 0.9422 - val_loss: 1.8382 - val_accuracy: 0.2500\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.2850 - accuracy: 0.9566 - val_loss: 1.7676 - val_accuracy: 0.2596\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.2578 - accuracy: 0.9663 - val_loss: 1.7455 - val_accuracy: 0.2500\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 101ms/step - loss: 0.2324 - accuracy: 0.9711 - val_loss: 1.7754 - val_accuracy: 0.2308\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.2146 - accuracy: 0.9735 - val_loss: 1.7925 - val_accuracy: 0.2404\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1928 - accuracy: 0.9759 - val_loss: 1.8069 - val_accuracy: 0.2596\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 91ms/step - loss: 0.1760 - accuracy: 0.9783 - val_loss: 1.7077 - val_accuracy: 0.2885\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.1610 - accuracy: 0.9807 - val_loss: 1.7369 - val_accuracy: 0.2981\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.1465 - accuracy: 0.9807 - val_loss: 1.9062 - val_accuracy: 0.2404\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.1346 - accuracy: 0.9855 - val_loss: 1.9702 - val_accuracy: 0.2404\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.1235 - accuracy: 0.9880 - val_loss: 1.9334 - val_accuracy: 0.2404\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.1137 - accuracy: 0.9904 - val_loss: 1.8991 - val_accuracy: 0.2596\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 118ms/step - loss: 0.1056 - accuracy: 0.9904 - val_loss: 1.9125 - val_accuracy: 0.2596\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0974 - accuracy: 0.9928 - val_loss: 1.9993 - val_accuracy: 0.2404\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0900 - accuracy: 0.9928 - val_loss: 2.0991 - val_accuracy: 0.2404\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 121ms/step - loss: 0.0840 - accuracy: 0.9928 - val_loss: 2.1477 - val_accuracy: 0.2404\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0780 - accuracy: 0.9928 - val_loss: 2.1076 - val_accuracy: 0.2404\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 117ms/step - loss: 0.0730 - accuracy: 0.9928 - val_loss: 2.0195 - val_accuracy: 0.2500\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 120ms/step - loss: 0.0681 - accuracy: 0.9928 - val_loss: 2.0889 - val_accuracy: 0.2404\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0624 - accuracy: 0.9952 - val_loss: 2.2601 - val_accuracy: 0.2404\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0582 - accuracy: 0.9952 - val_loss: 2.3144 - val_accuracy: 0.2404\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0537 - accuracy: 0.9952 - val_loss: 2.2935 - val_accuracy: 0.2404\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0496 - accuracy: 0.9976 - val_loss: 2.2809 - val_accuracy: 0.2404\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0464 - accuracy: 0.9976 - val_loss: 2.2992 - val_accuracy: 0.2404\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 99ms/step - loss: 0.0436 - accuracy: 0.9976 - val_loss: 2.3473 - val_accuracy: 0.2404\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 111ms/step - loss: 0.0408 - accuracy: 0.9976 - val_loss: 2.3774 - val_accuracy: 0.2404\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 139ms/step - loss: 0.0384 - accuracy: 0.9976 - val_loss: 2.3785 - val_accuracy: 0.2404\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0364 - accuracy: 0.9976 - val_loss: 2.3775 - val_accuracy: 0.2404\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0344 - accuracy: 0.9976 - val_loss: 2.4186 - val_accuracy: 0.2404\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0327 - accuracy: 0.9976 - val_loss: 2.4709 - val_accuracy: 0.2404\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0310 - accuracy: 0.9976 - val_loss: 2.4811 - val_accuracy: 0.2308\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 106ms/step - loss: 0.0296 - accuracy: 0.9976 - val_loss: 2.4860 - val_accuracy: 0.2308\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0281 - accuracy: 0.9976 - val_loss: 2.4912 - val_accuracy: 0.2404\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 129ms/step - loss: 0.0268 - accuracy: 0.9976 - val_loss: 2.4996 - val_accuracy: 0.2404\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 116ms/step - loss: 0.0255 - accuracy: 0.9976 - val_loss: 2.5146 - val_accuracy: 0.2404\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0245 - accuracy: 0.9976 - val_loss: 2.5440 - val_accuracy: 0.2404\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 102ms/step - loss: 0.0234 - accuracy: 0.9976 - val_loss: 2.5842 - val_accuracy: 0.2404\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 114ms/step - loss: 0.0224 - accuracy: 0.9976 - val_loss: 2.6177 - val_accuracy: 0.2308\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0216 - accuracy: 0.9976 - val_loss: 2.6228 - val_accuracy: 0.2308\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0207 - accuracy: 0.9976 - val_loss: 2.6301 - val_accuracy: 0.2308\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 107ms/step - loss: 0.0199 - accuracy: 0.9976 - val_loss: 2.6186 - val_accuracy: 0.2404\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0190 - accuracy: 0.9976 - val_loss: 2.6399 - val_accuracy: 0.2404\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0183 - accuracy: 0.9976 - val_loss: 2.6896 - val_accuracy: 0.2404\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.7204 - val_accuracy: 0.2404\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 2.7279 - val_accuracy: 0.2404\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 2.7333 - val_accuracy: 0.2596\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.7461 - val_accuracy: 0.2596\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 2.7613 - val_accuracy: 0.2596\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.7762 - val_accuracy: 0.2692\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 2.8045 - val_accuracy: 0.2596\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 2.8190 - val_accuracy: 0.2596\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 2.8366 - val_accuracy: 0.2596\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 87ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.8343 - val_accuracy: 0.2596\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.8257 - val_accuracy: 0.2692\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 146ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.8238 - val_accuracy: 0.2692\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 98ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 2.8421 - val_accuracy: 0.2692\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.8627 - val_accuracy: 0.2692\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 2.8847 - val_accuracy: 0.2692\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 2.9010 - val_accuracy: 0.2692\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 115ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 2.9132 - val_accuracy: 0.2692\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 113ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 2.9297 - val_accuracy: 0.2692\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 2.9323 - val_accuracy: 0.2692\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 93ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 2.9408 - val_accuracy: 0.2692\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 2.9673 - val_accuracy: 0.2692\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.9889 - val_accuracy: 0.2596\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 97ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.9911 - val_accuracy: 0.2596\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 105ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.9847 - val_accuracy: 0.2692\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.9960 - val_accuracy: 0.2692\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 96ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 3.0141 - val_accuracy: 0.2692\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 112ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.0202 - val_accuracy: 0.2692\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 104ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.0267 - val_accuracy: 0.2692\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 95ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.0310 - val_accuracy: 0.2692\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 110ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 3.0376 - val_accuracy: 0.2692\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0359 - val_accuracy: 0.2692\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 3.0436 - val_accuracy: 0.2596\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 94ms/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 3.0790 - val_accuracy: 0.2596\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 103ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1150 - val_accuracy: 0.2596\n",
      "Test loss: 1.4556633234024048\n",
      "Test accuracy: 0.5757575631141663\n"
     ]
    }
   ],
   "source": [
    "def model_evaluation():\n",
    "    model, X_test, y_test = train_model()\n",
    "    score = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n",
    "model_evaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e48261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a4e4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d1168",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
